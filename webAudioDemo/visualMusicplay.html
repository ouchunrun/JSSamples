<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8"/>
        <meta name="Author" contect="GabrielChen">
        <meta name="keywords" contect="Web Audio API">
        <title>可视化音乐播放</title>
        <style>
            #canvasOne {
                border: 1px solid #ddd;
            }
        </style>
    </head>

    <body onload="init();">
        <h1>从audio源获取声音</h1>

        <audio src="./public/music/轻逸先生 - 其实你并没有那么需要爱情.mp3" controls="controls" id="audio">
            你的浏览器不支持audio标签
        </audio><button id="start">点击恢复播放</button>

        <h1>audio读取声音频域图</h1>
        <canvas id="canvasFormAudio" width="640"></canvas>


        <h1>频域图模仿</h1>
        <canvas id="canvasOne" width="640"></canvas>

        <h1>圆形声波图</h1>
        <canvas id="canvasTwo" width="800" height="800"></canvas>
    </body>

    <script>
        // 兼容处理
        window.navigator.mediaDevices.getUserMedia = (navigator.mediaDevices.getUserMedia || navigator.mediaDevices.webkitGetUserMedia || navigator.mediaDevices.mozGetUserMedia || navigator.mediaDevices.msGetUserMedia);
        window.AudioContext = window.AudioContext || window.webkitAudioContext;
        // var audioCtx = new AudioContext();
        var ctx;
        var ctx2;
        var audioContext;
        var analyser;
        var mic;
        var canvasOne;
        var canvasTwo;
        var constraints = {audio: true};

        <!------------------------------------ 从麦克风设备读取声音的波形图显示 -------------------------------->
        function init() {
            canvasOne = document.getElementById('canvasOne');
            ctx = canvasOne.getContext("2d");
            canvasTwo = document.getElementById('canvasTwo');
            ctx2 = canvasTwo.getContext("2d");

            navigator.mediaDevices.getUserMedia(constraints)
                .then(function (stream) {
                    audioContext = new AudioContext();
                    console.log("audioCtx state: ", audioContext.state);
                    mic = audioContext.createMediaStreamSource(stream);
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 256;   // 傅里叶变换参数
                    mic.connect(analyser);
                    drawSpectrum();
                })
                .catch(function (error) {
                    console.error(error.toString());
                });
        }

        function drawSpectrum() {
            var WIDTH = canvasOne.width;
            var HEIGHT = canvasOne.height;

            var array = new Uint8Array(128);
            analyser.getByteFrequencyData(array);
            ctx.clearRect(0, 0, WIDTH, HEIGHT);
            ctx2.clearRect(0, 0, 800, 800);
            for (var i = 0; i < (array.length); i++) {
                var value = array[i];
                ctx.fillRect(i * 5, HEIGHT - value, 3, HEIGHT);
            }

            for (var i = 0; i < (array.length); i++) {
                var value = array[i];
                ctx2.beginPath();
                ctx2.arc(300, 300, value, 0, 360, false);
                ctx2.lineWidth = 5;
                ctx2.strokeStyle = "rgba(" + value + "," + value + ",0,0.2)";
                ctx2.stroke();//画空心圆
                ctx2.closePath();

            }
            requestAnimationFrame(drawSpectrum);
        }


        <!-------------------------------------------- 从audio读取声音的波形图显示 -------------------------------->
        var context1;
        var analyserfa;
        var myAudio;
        var canvasFormAudio = document.getElementById('canvasFormAudio');
        var ctxfa = canvasFormAudio.getContext("2d");

        /*解决Analyser state变成suspended无法再次播放，且波形图无法显示 */
        document.getElementById('start').onclick = function () {
            context1.resume().then(function () {
                console.log("context1 resume state: ", context1.state);
                document.getElementById('audio').click();
                myAudio.play()
            }).catch(function (error) {
                console.error(error.toString());
            });
        };

        window.addEventListener('load', function (e) {
            myAudio = document.getElementById("audio");
            context1 = new AudioContext();
            analyserfa = context1.createAnalyser();

            console.log("context1 state: ", context1.state);
            var source = context1.createMediaElementSource(myAudio);
            source.connect(analyserfa);
            analyserfa.connect(context1.destination);
            drawSpectrumfa();

        }, false);

        function drawSpectrumfa() {
            var WIDTH = canvasFormAudio.width;
            var HEIGHT = canvasFormAudio.height;

            var array = new Uint8Array(128);
            analyserfa.getByteFrequencyData(array);   // 频域
            // analyserfa.getByteTimeDomainData(array);    // 时域

            // 获取所有频率振幅
            var average = getAverageFrequency(array);

            ctxfa.clearRect(0, 0, WIDTH, HEIGHT);
            for (var i = 0; i < (array.length); i++) {
                var value = array[i];
                ctxfa.fillRect(i * 5, HEIGHT - value, 3, HEIGHT);
            }

            requestAnimationFrame(drawSpectrumfa);
        }


        /* get all the frequency amplitudes */
        function getAverageFrequency(array) {
            var values = 0;
            var average;
            var length = array.length;

            for (var i = 0; i < length; i++) {
                values = values + array[i];
            }
            average = values / length;
            // console.warn("获得所有频率振幅的平均振幅：" + average);  speechRateCalculation

            return average;
        }
    </script>
</html>